{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Guille\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Guille\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "import math\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Cargar un modelo de incrustaciones de palabras pre-entrenado (Word2Vec en este caso)\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Rest_google.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Repositorios\\repositorio-henry\\google-yelp08\\ML\\recomendation_final.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39mRest_google.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\ProyectML\\lib\\site-packages\\pandas\\io\\parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    510\u001b[0m     path,\n\u001b[0;32m    511\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m    512\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    513\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[0;32m    514\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    515\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    516\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\ProyectML\\lib\\site-packages\\pandas\\io\\parquet.py:220\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    218\u001b[0m     to_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39msplit_blocks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    221\u001b[0m     path,\n\u001b[0;32m    222\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    223\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    224\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     pa_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    228\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    229\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\ProyectML\\lib\\site-packages\\pandas\\io\\parquet.py:110\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m handles \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    102\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[0;32m    103\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m    111\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     path_or_handle \u001b[39m=\u001b[39m handles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Guille\\anaconda3\\envs\\ProyectML\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Rest_google.parquet'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('Rest_google.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_text):\n",
    "    # Tokenizaci贸n y limpieza de texto\n",
    "    tokens = word_tokenize(input_text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(user_location, restaurant_location):\n",
    "    # Extraer las coordenadas de latitud y longitud del usuario y del restaurante\n",
    "    user_lat, user_lon = user_location\n",
    "    restaurant_lat, restaurant_lon = restaurant_location\n",
    "\n",
    "    # Radio de la Tierra en kil贸metros\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convertir latitud y longitud de grados a radianes\n",
    "    user_lat = math.radians(user_lat)\n",
    "    user_lon = math.radians(user_lon)\n",
    "    restaurant_lat = math.radians(restaurant_lat)\n",
    "    restaurant_lon = math.radians(restaurant_lon)\n",
    "\n",
    "    # Diferencia en latitud y longitud\n",
    "    dlon = restaurant_lon - user_lon\n",
    "    dlat = restaurant_lat - user_lat\n",
    "\n",
    "    # F贸rmula de Haversine para calcular la distancia\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(user_lat) * math.cos(restaurant_lat) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    # Distancia en kil贸metros\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_restaurants(input_text, df, word2vec_model, user_location):\n",
    "    input_keywords = preprocess_input(input_text)\n",
    "\n",
    "    # Obtener representaciones vectoriales para las palabras clave\n",
    "    keyword_vectors = [word2vec_model[word] for word in input_keywords if word in word2vec_model.vocab]\n",
    "\n",
    "    # Calcular la media de los vectores de palabras clave\n",
    "    if keyword_vectors:\n",
    "        input_vector = np.mean(keyword_vectors, axis=0)\n",
    "        # Calcular la similitud de coseno entre el input y las categor铆as de los restaurantes\n",
    "        df['similarity'] = df['category'].apply(lambda x: cosine_similarity([input_vector], [np.mean([word2vec_model[word] for word in x if word in word2vec_model.vocab], axis=0)])[0][0])\n",
    "\n",
    "        # Calcular la distancia desde la ubicaci贸n del usuario\n",
    "        df['distance'] = df['coord'].apply(lambda x: calculate_distance(user_location, x))\n",
    "\n",
    "        # Ponderar similitud y distancia para obtener una puntuaci贸n final\n",
    "        df['score'] = df['similarity'] + 0.5 * (1 - df['distance'])\n",
    "\n",
    "        # Ordenar por puntuaci贸n\n",
    "        recommended_restaurants = df.sort_values(by='score', ascending=False).head(5)\n",
    "        return recommended_restaurants[['nombre_restaurante', 'categorias', 'ubicacion']]\n",
    "    else:\n",
    "        return \"No se encontraron palabras clave v谩lidas en el input.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Repositorios\\repositorio-henry\\google-yelp08\\ML\\recomendation_final.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI want to eat sushi and pasta\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m user_location \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mUserLocation\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Reemplaza con la ubicaci贸n real del usuario\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m recommended_restaurants \u001b[39m=\u001b[39m recommend_restaurants(input_text, df, word2vec_model, (\u001b[39m44.3069541\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m89.8457834\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(recommended_restaurants)\n",
      "\u001b[1;32mc:\\Repositorios\\repositorio-henry\\google-yelp08\\ML\\recomendation_final.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_keywords \u001b[39m=\u001b[39m preprocess_input(input_text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Obtener representaciones vectoriales para las palabras clave\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m keyword_vectors \u001b[39m=\u001b[39m [word2vec_model[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m input_keywords \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word2vec_model\u001b[39m.\u001b[39mvocab]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Calcular la media de los vectores de palabras clave\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m keyword_vectors:\n",
      "\u001b[1;32mc:\\Repositorios\\repositorio-henry\\google-yelp08\\ML\\recomendation_final.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_keywords \u001b[39m=\u001b[39m preprocess_input(input_text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Obtener representaciones vectoriales para las palabras clave\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m keyword_vectors \u001b[39m=\u001b[39m [word2vec_model[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m input_keywords \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word2vec_model\u001b[39m.\u001b[39;49mvocab]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Calcular la media de los vectores de palabras clave\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositorios/repositorio-henry/google-yelp08/ML/recomendation_final.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m keyword_vectors:\n",
      "File \u001b[1;32mc:\\Users\\guill\\anaconda3\\envs\\ProyectML\\lib\\site-packages\\gensim\\models\\keyedvectors.py:734\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvocab\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    735\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse KeyedVector\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "input_text = \"I want to eat sushi and pasta\"\n",
    "user_location = 'UserLocation'  # Reemplaza con la ubicaci贸n real del usuario\n",
    "recommended_restaurants = recommend_restaurants(input_text, df, word2vec_model, (44.3069541, -89.8457834))\n",
    "print(recommended_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProyectML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
